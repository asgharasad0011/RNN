{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "nVEBtvmG3ypF"
      },
      "outputs": [],
      "source": [
        "origional_text = \"\"\"Pakistan is a beautiful country.\n",
        "It has mountains, rivers, and deserts.\n",
        "The people of Pakistan are friendly and hardworking.\n",
        "Karachi is the largest city, while Islamabad is the capital.\"\"\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3N-fc1A4WmC",
        "outputId": "9a3897ef-ace9-4481-f81b-926972c6a9c5"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "text = origional_text .lower()\n",
        "text = re.sub(r'[^a-z\\s]', '', text)\n",
        "tokens = word_tokenize(text)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "260ubKoU4GvZ",
        "outputId": "ac176a80-9760-432a-b4d7-f1c38e5a3209"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['pakistan', 'is', 'a', 'beautiful', 'country', 'it', 'has', 'mountains', 'rivers', 'and', 'deserts', 'the', 'people', 'of', 'pakistan', 'are', 'friendly', 'and', 'hardworking', 'karachi', 'is', 'the', 'largest', 'city', 'while', 'islamabad', 'is', 'the', 'capital']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.tokenize import sent_tokenize\n",
        "\n",
        "# Step 1 — Split into sentences\n",
        "sentences = sent_tokenize(origional_text)\n",
        "\n",
        "# Step 2 — Tokenize each sentence\n",
        "tokenized_sentences = [word_tokenize(sentence.lower()) for sentence in sentences]\n",
        "\n",
        "print(tokenized_sentences)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D7suLw1947cm",
        "outputId": "8af1c572-8677-4a0d-8e55-7187491a965f"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['pakistan', 'is', 'a', 'beautiful', 'country', '.'], ['it', 'has', 'mountains', ',', 'rivers', ',', 'and', 'deserts', '.'], ['the', 'people', 'of', 'pakistan', 'are', 'friendly', 'and', 'hardworking', '.'], ['karachi', 'is', 'the', 'largest', 'city', ',', 'while', 'islamabad', 'is', 'the', 'capital', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2UR95zd6rQt",
        "outputId": "227a4826-f94a-4020-c529-e76ef9095a72"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.2)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.4.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.0)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "qeDgkzvP5nYs"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Word2Vec model\n",
        "w2v_model = Word2Vec(tokenized_sentences, vector_size=50, window=3, min_count=1, sg=1)\n",
        "\n",
        "# Example embedding\n",
        "print(w2v_model.wv.key_to_index)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hlacKobC6o7j",
        "outputId": "beab4b18-57b9-4bf7-808c-6fa56227b51d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'.': 0, 'the': 1, ',': 2, 'is': 3, 'and': 4, 'pakistan': 5, 'capital': 6, 'islamabad': 7, 'while': 8, 'city': 9, 'largest': 10, 'karachi': 11, 'hardworking': 12, 'friendly': 13, 'are': 14, 'of': 15, 'people': 16, 'deserts': 17, 'rivers': 18, 'mountains': 19, 'has': 20, 'it': 21, 'country': 22, 'beautiful': 23, 'a': 24}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(w2v_model.vector_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JE5nDdbc8ZxV",
        "outputId": "0f48d4fd-40db-4e78-d24f-13eeeeeb65ca"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(w2v_model.wv[1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vNvonGtt62S1",
        "outputId": "e7d58353-7547-4603-f053-26e826898cd6"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.01631119  0.00896482 -0.00828904  0.00163445  0.01697237 -0.00891939\n",
            "  0.00904504 -0.0135247  -0.00709723  0.01879099 -0.00315681  0.00064119\n",
            " -0.00825248 -0.01537667 -0.00300022  0.00496796 -0.00175528  0.01107437\n",
            " -0.00550603  0.00448923  0.01091611  0.01668236 -0.00287032 -0.01836924\n",
            "  0.00872761  0.00112683  0.01488191 -0.00160852 -0.00528974 -0.01751091\n",
            " -0.00175221  0.00566612  0.01082291  0.01410667 -0.0114204   0.00371449\n",
            "  0.01223238 -0.0096161  -0.00622663  0.01358508  0.00326071  0.00038033\n",
            "  0.00693194  0.00042717  0.0192661   0.01013025 -0.01779987 -0.01412022\n",
            "  0.00178293  0.0127855 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(w2v_model.wv[\"the\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsVnkFJZ7mSW",
        "outputId": "b9f7afbe-3dd0-4973-dfb4-a96208abe20c"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[-0.01631119  0.00896482 -0.00828904  0.00163445  0.01697237 -0.00891939\n",
            "  0.00904504 -0.0135247  -0.00709723  0.01879099 -0.00315681  0.00064119\n",
            " -0.00825248 -0.01537667 -0.00300022  0.00496796 -0.00175528  0.01107437\n",
            " -0.00550603  0.00448923  0.01091611  0.01668236 -0.00287032 -0.01836924\n",
            "  0.00872761  0.00112683  0.01488191 -0.00160852 -0.00528974 -0.01751091\n",
            " -0.00175221  0.00566612  0.01082291  0.01410667 -0.0114204   0.00371449\n",
            "  0.01223238 -0.0096161  -0.00622663  0.01358508  0.00326071  0.00038033\n",
            "  0.00693194  0.00042717  0.0192661   0.01013025 -0.01779987 -0.01412022\n",
            "  0.00178293  0.0127855 ]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# Create vocabulary and mapping\n",
        "vocab = list(w2v_model.wv.index_to_key)\n",
        "word_to_index = {word: i for i, word in enumerate(vocab)}\n",
        "\n",
        "# Convert text into sequences of indexes\n",
        "sequence = [word_to_index[word] for word in tokens if word in word_to_index]\n",
        "\n",
        "X = []\n",
        "y = []\n",
        "for i in range(1, len(sequence)):\n",
        "    X.append(sequence[:i])\n",
        "    y.append(sequence[i])\n",
        "\n",
        "# Pad sequences to equal length\n",
        "X = pad_sequences(X, maxlen=10, padding='pre')\n",
        "y = to_categorical(y, num_classes=len(vocab))\n"
      ],
      "metadata": {
        "id": "6G9ICxms71jb"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, Embedding\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=len(vocab), output_dim=50, weights=[w2v_model.wv.vectors], trainable=False))\n",
        "model.add(SimpleRNN(64, return_sequences=False))\n",
        "model.add(Dense(len(vocab), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(X, y, epochs=200, verbose=0)\n"
      ],
      "metadata": {
        "id": "xrXyADT09y5c",
        "outputId": "f3ed3aac-7e8f-4ac2-ffa3-0295a18bd013",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7b0727790b30>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "def predict_next_word(seed_text):\n",
        "    tokens = [word_to_index[w] for w in seed_text.lower().split() if w in word_to_index]\n",
        "    tokens = pad_sequences([tokens], maxlen=10, padding='pre')\n",
        "    pred = np.argmax(model.predict(tokens, verbose=0))\n",
        "    return vocab[pred]\n",
        "\n",
        "print(predict_next_word(\"pakistan\"))\n"
      ],
      "metadata": {
        "id": "sbIJ7_7L91MI",
        "outputId": "d79e7188-043a-4c4a-93f8-e7953488a411",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N50OSCJ49-fL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}